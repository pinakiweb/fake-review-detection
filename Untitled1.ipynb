{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from nltk import bigrams,trigrams\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from textblob import TextBlob\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets # https://www.tensorflow.org/api_docs/python/tf/keras/datasets\n",
    "from tensorflow.keras import layers # https://www.tensorflow.org/api_docs/python/tf/keras/layers\n",
    "from tensorflow.keras import activations # https://www.tensorflow.org/api_docs/python/tf/keras/activations\n",
    "from tensorflow.keras import initializers # https://www.tensorflow.org/api_docs/python/tf/keras/initializers\n",
    "from tensorflow.keras import losses # https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
    "from tensorflow.keras import metrics # https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n",
    "from tensorflow.keras import optimizers # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
    "from tensorflow.keras import regularizers # https://www.tensorflow.org/api_docs/python/tf/keras/regularizers\n",
    "from tensorflow.keras.optimizers import schedules # https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules\n",
    "from tensorflow.keras import callbacks # https://www.tensorflow.org/api_docs/python/tf/keras/callbacks\n",
    "from tensorflow.keras import utils # https://www.tensorflow.org/api_docs/python/tf/keras/utils\n",
    "from tensorflow.keras import models # https://www.tensorflow.org/api_docs/python/tf/keras/models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>stdrating</th>\n",
       "      <th>clusterid</th>\n",
       "      <th>meanSimilarity</th>\n",
       "      <th>varOfSimilarity</th>\n",
       "      <th>meanRating</th>\n",
       "      <th>numberOfReviews</th>\n",
       "      <th>avgNoOfWords</th>\n",
       "      <th>totalReviews</th>\n",
       "      <th>isSingleton</th>\n",
       "      <th>posReviewRatio</th>\n",
       "      <th>negReviewRatio</th>\n",
       "      <th>avgNoOfReviews</th>\n",
       "      <th>maxNoOfReviews</th>\n",
       "      <th>dateVariance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.195833</td>\n",
       "      <td>0.395833</td>\n",
       "      <td>143</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>141</td>\n",
       "      <td>0.043510</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>4.009524</td>\n",
       "      <td>210</td>\n",
       "      <td>37.410256</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>1.625</td>\n",
       "      <td>3</td>\n",
       "      <td>1.360395e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>163</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>74</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>4.009524</td>\n",
       "      <td>210</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.003740e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.328718</td>\n",
       "      <td>115</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>167</td>\n",
       "      <td>0.047143</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>4.009524</td>\n",
       "      <td>210</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.555134</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>315</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>378</td>\n",
       "      <td>0.076343</td>\n",
       "      <td>0.005720</td>\n",
       "      <td>4.009524</td>\n",
       "      <td>210</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.003740e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.138715</td>\n",
       "      <td>0.538294</td>\n",
       "      <td>420</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>992</td>\n",
       "      <td>0.062976</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>4.009524</td>\n",
       "      <td>210</td>\n",
       "      <td>86.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>2.618750e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity  subjectivity  wordCount  stdrating  clusterid  meanSimilarity  \\\n",
       "0  0.195833      0.395833        143   0.896514        141        0.043510   \n",
       "1  0.025000      0.650000        163   0.896514         74        0.067578   \n",
       "2  0.220000      0.328718        115   0.896514        167        0.047143   \n",
       "3  0.555134      0.776786        315   0.896514        378        0.076343   \n",
       "4  0.138715      0.538294        420   0.896514        992        0.062976   \n",
       "\n",
       "   varOfSimilarity  meanRating  numberOfReviews  avgNoOfWords  totalReviews  \\\n",
       "0         0.005451    4.009524              210     37.410256            39   \n",
       "1         0.005659    4.009524              210     27.000000             1   \n",
       "2         0.005273    4.009524              210     22.000000             2   \n",
       "3         0.005720    4.009524              210     52.000000             1   \n",
       "4         0.005454    4.009524              210     86.200000             5   \n",
       "\n",
       "   isSingleton  posReviewRatio  negReviewRatio  avgNoOfReviews  \\\n",
       "0            0        0.974359        0.025641           1.625   \n",
       "1            1        1.000000        0.000000           1.000   \n",
       "2            0        1.000000        0.000000           2.000   \n",
       "3            1        1.000000        0.000000           1.000   \n",
       "4            0        0.800000        0.200000           1.000   \n",
       "\n",
       "   maxNoOfReviews  dateVariance  \n",
       "0               3  1.360395e+02  \n",
       "1               1  2.003740e+06  \n",
       "2               2  0.000000e+00  \n",
       "3               1  2.003740e+06  \n",
       "4               1  2.618750e+01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading all the 17 features\n",
    "all_features = pd.read_csv(\"featuresAll.csv\")\n",
    "all_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(359052, 17)\n"
     ]
    }
   ],
   "source": [
    "all_features = all_features.to_numpy()\n",
    "print(all_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359052\n"
     ]
    }
   ],
   "source": [
    "#reading the reviews\n",
    "file1 = open(\"YelpNYC/reviewContent\")\n",
    "all_stop_words = stopwords.words('english')\n",
    "data1 = []\n",
    "for s in file1:\n",
    "    row = s[17:]\n",
    "    row = re.sub('[^a-zA-Z0-9 \\n\\..]', '', row)\n",
    "    row = ' '.join([word for word in row.split() if word not in all_stop_words])\n",
    "    data1.append(row)\n",
    "file1.close()\n",
    "print(len(data1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359052, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading all the labels\n",
    "labels = pd.read_csv(\"labels.csv\")\n",
    "Y = labels.to_numpy()\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tfidf vectorization to convert the reviews into features\n",
    "tfidf_vector = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = tfidf_vector.fit_transform(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the number of features\n",
    "svd = TruncatedSVD(n_components = 100)\n",
    "X_tfidf = svd.fit_transform(X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359052, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#putting all the features together\n",
    "# X1 = np.hstack((X_tfidf,all_features))\n",
    "X1 = all_features\n",
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 144       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(8,input_dim = len(X1[0,:]),activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11221/11221 [==============================] - 14s 1ms/step - loss: 30.8898 - accuracy: 0.8868\n",
      "Epoch 2/15\n",
      "11221/11221 [==============================] - 14s 1ms/step - loss: 0.3186 - accuracy: 0.8968\n",
      "Epoch 3/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3095 - accuracy: 0.8974\n",
      "Epoch 4/15\n",
      "11221/11221 [==============================] - 11s 998us/step - loss: 0.3149 - accuracy: 0.8970\n",
      "Epoch 5/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3240 - accuracy: 0.8975\n",
      "Epoch 6/15\n",
      "11221/11221 [==============================] - 13s 1ms/step - loss: 0.3211 - accuracy: 0.8978\n",
      "Epoch 7/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3173 - accuracy: 0.8968\n",
      "Epoch 8/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3101 - accuracy: 0.8970\n",
      "Epoch 9/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3110 - accuracy: 0.8972\n",
      "Epoch 10/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3055 - accuracy: 0.8973\n",
      "Epoch 11/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3034 - accuracy: 0.8980\n",
      "Epoch 12/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3069 - accuracy: 0.8966\n",
      "Epoch 13/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3033 - accuracy: 0.8977\n",
      "Epoch 14/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3201 - accuracy: 0.8977\n",
      "Epoch 15/15\n",
      "11221/11221 [==============================] - 12s 1ms/step - loss: 0.3122 - accuracy: 0.8965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd0a9d001f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X1, y=Y, epochs=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 117)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               30208     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 64,769\n",
      "Trainable params: 64,001\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models1 = tf.keras.Sequential([\n",
    "\n",
    "    \n",
    "    layers.Flatten(input_dim = len(X1[0,:])), \n",
    "    \n",
    "    layers.Dense(units=256, activation=None), \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(activations.relu),\n",
    "    \n",
    "    layers.Dense(units=128, activation=None), \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(activations.relu),\n",
    "    \n",
    "    layers.Dense(units=1, activation=activations.sigmoid) \n",
    "])\n",
    "\n",
    "models1.summary()\n",
    "\n",
    "models1.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001), \n",
    "    loss=losses.BinaryCrossentropy(), \n",
    "    metrics=['accuracy']\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2245/2245 [==============================] - 3s 964us/step - loss: 6867.4208 - accuracy: 0.6741\n",
      "Epoch 2/5\n",
      "2245/2245 [==============================] - 2s 991us/step - loss: 0.5162 - accuracy: 0.8937\n",
      "Epoch 3/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.3535 - accuracy: 0.8960\n",
      "Epoch 4/5\n",
      "2245/2245 [==============================] - 2s 988us/step - loss: 0.3080 - accuracy: 0.8964\n",
      "Epoch 5/5\n",
      "2245/2245 [==============================] - 2s 981us/step - loss: 0.2995 - accuracy: 0.8983\n",
      "Fold 1 Accuracy: 0.8972720056815808  Precision:  0.0  Recall:  0.0  F1-Score:  0.0\n",
      "Epoch 1/5\n",
      "  37/2245 [..............................] - ETA: 3s - loss: 0.3182 - accuracy: 0.8894 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sabu/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2245/2245 [==============================] - 2s 982us/step - loss: 0.3044 - accuracy: 0.8965\n",
      "Epoch 2/5\n",
      "2245/2245 [==============================] - 2s 984us/step - loss: 0.3105 - accuracy: 0.8965\n",
      "Epoch 3/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.3151 - accuracy: 0.8966\n",
      "Epoch 4/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.3060 - accuracy: 0.8967\n",
      "Epoch 5/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.3008 - accuracy: 0.8968: 0s - loss: 0.3009 - accuracy\n",
      "Fold 2 Accuracy: 0.8972859311247581  Precision:  1.0  Recall:  0.00013555645926528398  F1-Score:  0.0002710761724044456\n",
      "Epoch 1/5\n",
      "2245/2245 [==============================] - 2s 985us/step - loss: 0.3000 - accuracy: 0.8971\n",
      "Epoch 2/5\n",
      "2245/2245 [==============================] - 2s 988us/step - loss: 0.2962 - accuracy: 0.8969\n",
      "Epoch 3/5\n",
      "2245/2245 [==============================] - 2s 988us/step - loss: 0.2947 - accuracy: 0.8969\n",
      "Epoch 4/5\n",
      "2245/2245 [==============================] - 2s 988us/step - loss: 0.2959 - accuracy: 0.8970\n",
      "Epoch 5/5\n",
      "2245/2245 [==============================] - 2s 996us/step - loss: 0.2923 - accuracy: 0.8969\n",
      "Fold 3 Accuracy: 0.8970895418465394  Precision:  0.35555555555555557  Recall:  0.0021689033482445437  F1-Score:  0.004311506332524926\n",
      "Epoch 1/5\n",
      "2245/2245 [==============================] - 2s 998us/step - loss: 0.2919 - accuracy: 0.8971\n",
      "Epoch 2/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2927 - accuracy: 0.8968\n",
      "Epoch 3/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2926 - accuracy: 0.8969\n",
      "Epoch 4/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2948 - accuracy: 0.8968\n",
      "Epoch 5/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2924 - accuracy: 0.8966\n",
      "Fold 4 Accuracy: 0.8973541289513995  Precision:  0.6875  Recall:  0.0014911210519181239  F1-Score:  0.0029757879074800483\n",
      "Epoch 1/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2912 - accuracy: 0.8970\n",
      "Epoch 2/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2900 - accuracy: 0.8969\n",
      "Epoch 3/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2928 - accuracy: 0.8969\n",
      "Epoch 4/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2903 - accuracy: 0.8968\n",
      "Epoch 5/5\n",
      "2245/2245 [==============================] - 2s 1ms/step - loss: 0.2887 - accuracy: 0.8969\n",
      "Fold 5 Accuracy: 0.8971870213062247  Precision:  0.42105263157894735  Recall:  0.0021689033482445437  F1-Score:  0.004315576534052595\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "fold_no = 1\n",
    "for train_index, test_index in skf.split(X1, Y):\n",
    "    X_train = X1[train_index,:]\n",
    "    X_test = X1[test_index,:]\n",
    "    Y_train = Y[train_index,:]\n",
    "    Y_test = Y[test_index,:]\n",
    "    model.fit(X_train, Y_train, epochs=5,batch_size=128,)\n",
    "    predictions = model.predict(X_test)\n",
    "    print('Fold',str(fold_no),'Accuracy:',accuracy_score(Y_test,np.round(predictions)), ' Precision: ',precision_score(Y_test,np.round(predictions)), ' Recall: ',recall_score(Y_test,np.round(predictions)), ' F1-Score: ',f1_score(Y_test,np.round(predictions)))\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-gram vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_vector = CountVectorizer(ngram_range=(2, 2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "X_ngram = bigram_vector.fit_transform(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd2 = TruncatedSVD(n_components = 100)\n",
    "X_ngram = svd2.fit_transform(X_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.hstack((X_ngram,all_features))\n",
    "X2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models2 = tf.keras.Sequential([\n",
    "\n",
    "    \n",
    "    layers.Flatten(input_dim = len(X1[0,:])), \n",
    "    \n",
    "    layers.Dense(units=256, activation=None), \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(activations.relu),\n",
    "    \n",
    "    layers.Dense(units=128, activation=None), \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation(activations.relu),\n",
    "    \n",
    "    layers.Dense(units=1, activation=activations.sigmoid) \n",
    "])\n",
    "\n",
    "models2.summary()\n",
    "\n",
    "models2.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001), \n",
    "    loss=losses.BinaryCrossentropy(), \n",
    "    metrics=['accuracy']\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "fold_no = 1\n",
    "for train_index, test_index in skf.split(X2, Y):\n",
    "    X_train = X2[train_index,:]\n",
    "    X_test = X2[test_index,:]\n",
    "    Y_train = Y[train_index,:]\n",
    "    Y_test = Y[test_index,:]\n",
    "    history1 = models1.fit(X_train, Y_train, epochs=5,batch_size=128,)\n",
    "    predictions = models1.predict(X_test)\n",
    "    print('Fold',str(fold_no),'Accuracy:',accuracy_score(Y_test,np.round(predictions)), ' Precision: ',precision_score(Y_test,np.round(predictions)), ' Recall: ',recall_score(Y_test,np.round(predictions)), ' F1-Score: ',f1_score(Y_test,np.round(predictions)))\n",
    "    fold_no += 1=0.1,\n",
    ") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
